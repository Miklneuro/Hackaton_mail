import os
from pathlib import Path
import shutil
import json
import re
from email.header import decode_header

def decode_subject(subject: str) -> str:
    """–î–µ–∫–æ–¥–∏—Ä—É–µ—Ç —Ç–µ–º—É –ø–∏—Å—å–º–∞ –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ =?UTF-8?B?...= –≤ —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç."""
    if not subject:
        return ""
    
    try:
        decoded_parts = decode_header(subject)
        decoded_subject = ""
        for part, encoding in decoded_parts:
            if isinstance(part, bytes):
                if encoding:
                    decoded_subject += part.decode(encoding, errors='ignore')
                else:
                    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                    for enc in ['utf-8', 'cp1251', 'koi8-r', 'iso-8859-5']:
                        try:
                            decoded_subject += part.decode(enc, errors='strict')
                            break
                        except:
                            continue
                    else:
                        decoded_subject += part.decode('utf-8', errors='ignore')
            else:
                decoded_subject += str(part)
        return decoded_subject.strip()
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–º—ã '{subject[:30]}...': {e}")
        return subject

def extract_true_category_from_filename(filename: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏—Å—Ç–∏–Ω–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞."""
    if not filename:
        raise ValueError("–ò–º—è —Ñ–∞–π–ª–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
    
    # –£–¥–∞–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
    filename_without_ext = Path(filename).stem
    filename_lower = filename_without_ext.lower()
    
    # –ñ–ï–°–¢–ö–ò–ô –°–õ–û–í–ê–†–¨ –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–Ø –ê–ù–ì–õ–ò–ô–°–ö–ò–• –ò–ú–ï–ù –° –†–£–°–°–ö–ò–ú–ò –ö–ê–¢–ï–ì–û–†–ò–Ø–ú–ò
    # –ö–ª—é—á–∏ - –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞, –∑–Ω–∞—á–µ–Ω–∏—è - —Ä—É—Å—Å–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ new_cats.txt
    category_mapping = {
        # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
        'business_and_correspondence': '–ë–∏–∑–Ω–µ—Å-–∫–æ—Ä—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ü–∏—è',
        'financial_transactions_and_cheques': '–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏',
        'harm_content': '–ù–µ–ø—Ä–∏–µ–º–ª–µ–º—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç',
        'transport_and_travel': '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è',
        'newsletters': '–ù–æ–≤–æ—Å—Ç–Ω—ã–µ —Ä–∞—Å—Å—ã–ª–∫–∏',
        'registration_confirmation': '–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ',
        'promotional_mailing': '–†–µ–∫–ª–∞–º–Ω–∞—è —Ä–∞—Å—Å—ã–ª–∫–∞',
        'system_and_service_notifications': '–°–∏—Å—Ç–µ–º–Ω—ã–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è',
        'technical_support': '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞',
        'vacancies_careers': '–í–∞–∫–∞–Ω—Å–∏–∏ –∏ –∫–∞—Ä—å–µ—Ä–∞',
        'vacancies_and_career': '–í–∞–∫–∞–Ω—Å–∏–∏ –∏ –∫–∞—Ä—å–µ—Ä–∞',
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏—è "–î—Ä—É–≥–æ–µ" –¢–û–õ–¨–ö–û –¥–ª—è —Ñ–∞–π–ª–æ–≤ —Å 'other'
        'other': '–î—Ä—É–≥–æ–µ',
    }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä–µ
    for eng_name, rus_category in category_mapping.items():
        if eng_name in filename_lower:
            return rus_category
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ - –≤—ã–∑—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
    raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –¥–ª—è —Ñ–∞–π–ª–∞: {filename}")

def load_categories(file_path: str) -> dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞. –ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."""
    categories = {}
    with open(file_path, 'r', encoding='utf-8-sig') as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            
            if ":" in line:
                name, description = line.split(":", 1)
                name = name.strip()
                description = description.strip()
                
                # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –Ω–∞ –æ–±–æ–∏—Ö —è–∑—ã–∫–∞—Ö
                # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç—ã –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
                enhanced_description = f"{name}. {description}"
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ—Å—Ç–∏
                english_keywords = {
                    "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞": "technical support, help desk, IT support, troubleshooting",
                    "–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏": "financial transactions, payments, invoices, bills, accounting",
                    "–í–∞–∫–∞–Ω—Å–∏–∏ –∏ –∫–∞—Ä—å–µ—Ä–∞": "vacancies, careers, jobs, recruitment, CV, resume",
                    "–†–µ–∫–ª–∞–º–Ω–∞—è —Ä–∞—Å—Å—ã–ª–∫–∞": "advertising, marketing, promotion, commercial offers",
                    "–ù–æ–≤–æ—Å—Ç–Ω—ã–µ —Ä–∞—Å—Å—ã–ª–∫–∏": "newsletters, news, updates, announcements",
                    "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ": "registration, confirmation, account, verification",
                    "–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è": "transport, travel, tickets, booking, flights, hotels",
                    "–ù–µ–ø—Ä–∏–µ–º–ª–µ–º—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç": "spam, inappropriate content, adult, violence",
                    "–ë–∏–∑–Ω–µ—Å-–∫–æ—Ä—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ü–∏—è": "business correspondence, partners, contracts, negotiations",
                    "–°–∏—Å—Ç–µ–º–Ω—ã–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è": "system notifications, alerts, reports, automated messages",
                    "–î—Ä—É–≥–æ–µ": "other, miscellaneous, uncategorized"
                }
                
                if name in english_keywords:
                    enhanced_description += f". {english_keywords[name]}"
                
                categories[name] = enhanced_description
                print(f"   üìç {name}: {enhanced_description[:80]}...")
            else:
                categories[line] = line
    
    print(f"\nüìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {len(categories)}")
    return categories

def clear_output_folder(output_folder: str):
    """–û—á–∏—â–∞–µ—Ç –ø–∞–ø–∫—É data_output."""
    output_path = Path(output_folder)
    if output_path.exists():
        for file in output_path.iterdir():
            if file.is_file():
                file.unlink()
            elif file.is_dir():
                shutil.rmtree(file)
    else:
        output_path.mkdir(parents=True, exist_ok=True)

def save_results_json(results: list, output_file: str):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON —Ñ–∞–π–ª."""
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)

def save_results_csv(results: list, output_file: str):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CSV —Ñ–∞–π–ª."""
    import pandas as pd
    
    flat_data = []
    for result in results:
        row = {
            'filename': result.get('filename', ''),
            'subject': result.get('subject_decoded', result.get('subject', '')),
            'text_preview': result.get('body_preview', ''),
            'top_category': '',
            'top_score': 0.0,
            'processed': result.get('processed', False)
        }
        
        if result.get('categories'):
            row['top_category'] = result['categories'][0][0]
            row['top_score'] = result['categories'][0][1]
            
            for i, (cat, score) in enumerate(result['categories'][:5]):
                row[f'category_{i+1}'] = cat
                row[f'score_{i+1}'] = f"{score:.3f}"
        
        flat_data.append(row)
    
    df = pd.DataFrame(flat_data)
    df.to_csv(output_file, index=False, encoding='utf-8-sig')