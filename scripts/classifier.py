from sentence_transformers import SentenceTransformer, util
from utils import load_categories, decode_subject
import torch
import numpy as np
import os

# === –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ===
OTHER_CATEGORY_NAME = "–î—Ä—É–≥–æ–µ"  # –ò—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è
OTHER_CATEGORY_THRESHOLD = 0.4  #  –ø–æ—Ä–æ–≥
MIN_CONFIDENCE_FOR_DISPLAY = 0.3  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è

# === –ü–£–¢–ò ===
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
MODEL_CACHE_DIR = os.path.join(PROJECT_ROOT, 'model_cache')
os.makedirs(MODEL_CACHE_DIR, exist_ok=True)

print(f"ü§ñ –ö—ç—à –º–æ–¥–µ–ª–µ–π: {MODEL_CACHE_DIR}")

# === –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò ===
print("ü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Sentence Transformer...")

try:
    model_name = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'
    model = SentenceTransformer(
        model_name,
        cache_folder=MODEL_CACHE_DIR,
        device='cpu'
    )
    print(f"‚úÖ –ú–æ–¥–µ–ª—å '{model_name}' –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –≤ {MODEL_CACHE_DIR}")

except Exception as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")
    try:
        print("üîÑ –ü—Ä–æ–±—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å: paraphrase-multilingual-MiniLM-L12-v2")
        model = SentenceTransformer(
            'paraphrase-multilingual-MiniLM-L12-v2',
            cache_folder=MODEL_CACHE_DIR,
            device='cpu'
        )
        model_name = 'paraphrase-multilingual-MiniLM-L12-v2'
        print("‚úÖ –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    except Exception as e2:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {e2}")
        try:
            print("üîÑ –ü—Ä–æ–±—É–µ–º –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å: all-MiniLM-L6-v2")
            model = SentenceTransformer(
                'all-MiniLM-L6-v2',
                cache_folder=MODEL_CACHE_DIR,
                device='cpu'
            )
            model_name = 'all-MiniLM-L6-v2'
            print("‚úÖ –õ–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e3:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å")
            raise

# === –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ó–ê–ì–†–£–ñ–ï–ù–ù–û–ô –ú–û–î–ï–õ–ò ===
print(f"\nüìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏:")
print(f"   ‚Ä¢ –ò–º—è: {model_name}")
print(f"   ‚Ä¢ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {model.get_sentence_embedding_dimension()}")
print(f"   ‚Ä¢ –ú–∞–∫—Å. –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {model.max_seq_length}")
print(f"   ‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —è–∑—ã–∫–∏: –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è (–≤–∫–ª—é—á–∞—è RU/EN)")
print(f"\n‚öôÔ∏è  –õ–æ–≥–∏–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{OTHER_CATEGORY_NAME}':")
print(f"   ‚Ä¢ –ü–æ—Ä–æ–≥ –¥–ª—è '{OTHER_CATEGORY_NAME}': {OTHER_CATEGORY_THRESHOLD}")
print(f"   ‚Ä¢ –ï—Å–ª–∏ –ª—É—á—à–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è < {OTHER_CATEGORY_THRESHOLD} ‚Üí '{OTHER_CATEGORY_NAME}'")


def preprocess_text(text: str, subject: str = "") -> str:
    """–û—á–∏—â–∞–µ—Ç –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –ø–∏—Å—å–º–∞ —Å —É—á—ë—Ç–æ–º —Ç–µ–º—ã."""
    if not text and not subject:
        return ""

    try:
        decoded_subject = decode_subject(subject)
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–º—ã: {e}")
        decoded_subject = subject[:100] if subject else ""

    # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Ç–µ–º—É –∏ —Ç–µ–ª–æ –ø–∏—Å—å–º–∞
    enhanced_text = f"{decoded_subject}. {decoded_subject}. {decoded_subject}. {text}"

    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
    enhanced_text = ' '.join(enhanced_text.split())

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∞–∂–Ω—ã–µ —á–∞—Å—Ç–∏
    max_length = 4000
    if len(enhanced_text) > max_length:
        subject_part = f"{decoded_subject}. {decoded_subject}. {decoded_subject}."
        body_part = text[:max_length - len(subject_part) - 100]
        enhanced_text = subject_part + " " + body_part + "..."

    return enhanced_text


def safe_encode_text(text: str, max_retries: int = 2) -> torch.Tensor:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""
    for attempt in range(max_retries):
        try:
            return model.encode(text, convert_to_tensor=True, show_progress_bar=False)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
            if attempt == max_retries - 1:
                raise
            # –ü—Ä–æ–±—É–µ–º –æ–±—Ä–µ–∑–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª—É—á–∞–π —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
            text = text[:3000] + " [–¢–ï–ö–°–¢ –û–ë–†–ï–ó–ê–ù]"


def classify_emails(emails: list, categories_file: str, top_n: int = 5, threshold: float = 0.1) -> list:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–∏—Å–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º.
    :param threshold: –ü–æ—Ä–æ–≥ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–∏–∑–∫–∏—Ö —Å—Ö–æ–¥—Å—Ç–≤
    """
    try:
        categories = load_categories(categories_file)
        print(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {len(categories)}")

        if not categories:
            print("‚ùå –§–∞–π–ª –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø—É—Å—Ç!")
            return []

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {e}")
        return []

    results = []

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –æ–¥–∏–Ω —Ä–∞–∑
    print("üîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–π...")
    try:
        category_names = list(categories.keys())
        category_descriptions = list(categories.values())
        category_embeddings = model.encode(category_descriptions, convert_to_tensor=True)
        print(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã: {len(category_names)}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {e}")
        return results

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = {
        'total': 0,
        'successful': 0,
        'to_other': 0,
        'errors': 0,
        'confidences': []
    }

    for i, email in enumerate(emails, 1):
        email_result = {
            "filename": email.get("filename", f"email_{i}"),
            "subject": email.get("subject", ""),
            "processed": False,
            "categories": [],
            "error": None
        }
        
        try:
            filename = email.get("filename", f"email_{i}")
            print(f"\nüì® –û–±—Ä–∞–±–æ—Ç–∫–∞ {i}/{len(emails)}: {filename}")

            subject = email.get("subject", "")
            body = email.get("body", "")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–µ–∫—Å—Ç–∞
            if not body and not subject:
                print(f"‚ö†Ô∏è  –ü–∏—Å—å–º–æ –ø—É—Å—Ç–æ–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                email_result.update({
                    "subject_decoded": "",
                    "body_preview": "",
                    "categories": [("–ü—É—Å—Ç–æ–µ –ø–∏—Å—å–º–æ", 0.0)],
                    "error": "–ü—É—Å—Ç–æ–µ –ø–∏—Å—å–º–æ"
                })
                results.append(email_result)
                continue

            # –£—Å–∏–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é —Ç–µ–º—ã
            try:
                processed_text = preprocess_text(body, subject)
                decoded_subject = decode_subject(subject) if subject else ""
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
                # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç
                processed_text = body[:2000] if body else subject
                decoded_subject = subject[:100] if subject else ""

            print(f"üìù –¢–µ–∫—Å—Ç: {len(processed_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            if decoded_subject:
                print(f"üìÑ –¢–µ–º–∞ (–¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∞): {decoded_subject[:100]}...")

            if not processed_text.strip():
                print(f"‚ö†Ô∏è  –ü–∏—Å—å–º–æ –ø—É—Å—Ç–æ–µ –ø–æ—Å–ª–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏")
                email_result.update({
                    "subject_decoded": decoded_subject,
                    "body_preview": "",
                    "categories": [("–ü—É—Å—Ç–æ–µ –ø–∏—Å—å–º–æ", 0.0)],
                    "error": "–ü—É—Å—Ç–æ–µ –ø–∏—Å—å–º–æ –ø–æ—Å–ª–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏"
                })
                results.append(email_result)
                continue

            # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
            try:
                category_scores = classify_text(
                    processed_text,
                    categories,
                    category_embeddings,
                    top_n,
                    threshold
                )
                
                stats['total'] += 1
                stats['successful'] += 1

                if category_scores:
                    best_category, best_confidence = category_scores[0]
                    stats['confidences'].append(best_confidence)
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ª–æ–≥–∏–∫—É —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π "–î—Ä—É–≥–æ–µ"
                    if best_confidence < OTHER_CATEGORY_THRESHOLD:
                        # –ü–∏—Å—å–º–æ –∏–¥–µ—Ç –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—é "–î—Ä—É–≥–æ–µ"
                        final_category_scores = [(OTHER_CATEGORY_NAME, best_confidence)]
                        stats['to_other'] += 1
                        
                        if best_confidence < MIN_CONFIDENCE_FOR_DISPLAY:
                            quality_note = " (–û–ß–ï–ù–¨ –ù–ò–ó–ö–ê–Ø –£–í–ï–†–ï–ù–ù–û–°–¢–¨)"
                        else:
                            quality_note = ""
                        
                        print(f"üè∑Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {OTHER_CATEGORY_NAME} ({best_confidence:.3f}){quality_note}")
                        if best_confidence > 0.1:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±—ã–ª–∞ –∫–∞–∫–∞—è-—Ç–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                            print(f"   ‚ö†Ô∏è  –ò—Å—Ö–æ–¥–Ω–∞—è –ª—É—á—à–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: '{best_category}' —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {best_confidence:.3f}")
                    else:
                        # –û—Å—Ç–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                        final_category_scores = category_scores
                        top_cat, top_score = category_scores[0]
                        print(f"üè∑Ô∏è  –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {top_cat} ({top_score:.3f})")
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
                        if len(category_scores) > 1:
                            for j, (cat, score) in enumerate(category_scores[1:3], 2):
                                if score > threshold:
                                    print(f"   {j}. {cat} ({score:.3f})")
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ threshold
                    final_category_scores = [(OTHER_CATEGORY_NAME, 0.0)]
                    stats['to_other'] += 1
                    print(f"üè∑Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {OTHER_CATEGORY_NAME} (0.000)")
                    print(f"   ‚ö†Ô∏è  –ù–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ {threshold}")

                confidence_score = final_category_scores[0][1] if final_category_scores else 0.0

                email_result.update({
                    "subject_decoded": decoded_subject,
                    "body_preview": processed_text[:300],
                    "categories": final_category_scores,
                    "processed": True,
                    "confidence": confidence_score,
                    "is_other_category": (final_category_scores[0][0] == OTHER_CATEGORY_NAME if final_category_scores else False)
                })

            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–∏—Å—å–º–∞: {e}")
                stats['errors'] += 1
                email_result.update({
                    "subject_decoded": decoded_subject,
                    "body_preview": processed_text[:100] if processed_text else "",
                    "categories": [("–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏", 0.0)],
                    "error": f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)[:100]}"
                })

        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–∏—Å—å–º–∞: {e}")
            import traceback
            traceback.print_exc()
            stats['errors'] += 1
            email_result["error"] = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)[:100]}"

        results.append(email_result)

    # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò:")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ –ø–∏—Å–µ–º: {len(emails)}")
    print(f"   ‚Ä¢ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['successful']}")
    print(f"   ‚Ä¢ –° –æ—à–∏–±–∫–∞–º–∏: {stats['errors']}")
    
    if stats['successful'] > 0:
        success_rate = (stats['successful'] / len(emails)) * 100
        print(f"   ‚Ä¢ –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {success_rate:.1f}%")
    
    if stats['confidences']:
        avg_conf = sum(stats['confidences']) / len(stats['confidences'])
        print(f"üìä –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_conf:.3f}")
        print(f"üìä –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {min(stats['confidences']):.3f}")
        print(f"üìä –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {max(stats['confidences']):.3f}")
    
    if stats['total'] > 0:
        other_percentage = (stats['to_other'] / stats['total']) * 100
        print(f"üìä –ü–∏—Å–µ–º –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—é '{OTHER_CATEGORY_NAME}': {stats['to_other']}/{stats['total']} ({other_percentage:.1f}%)")

    return results


def classify_text(text: str, categories: dict, category_embeddings=None, top_n: int = 5,
                  threshold: float = 0.1) -> list:
    """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º. –ë–ï–ó SOFTMAX."""
    if not text.strip():
        return [("–ü—É—Å—Ç–æ–µ –ø–∏—Å—å–º–æ", 0.0)]

    try:
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        text_embedding = safe_encode_text(text)

        # –ï—Å–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã, –≤—ã—á–∏—Å–ª—è–µ–º –∏—Ö
        if category_embeddings is None:
            category_descriptions = list(categories.values())
            category_embeddings = model.encode(category_descriptions, convert_to_tensor=True)

        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        similarities = util.cos_sim(text_embedding, category_embeddings)[0]
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ [0, 1]
        similarities_np = similarities.cpu().numpy()
        normalized_similarities = (similarities_np + 1) / 2

        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = []
        category_names = list(categories.keys())

        for i, category_name in enumerate(category_names):
            confidence = float(normalized_similarities[i])
            results.append((category_name, confidence))

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        results.sort(key=lambda x: x[1], reverse=True)

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥
        normalized_threshold = (threshold + 1) / 2 if threshold < 0 else threshold
        filtered_results = [r for r in results if r[1] >= normalized_threshold]

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        return filtered_results[:top_n]

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, –≤—ã–∑—ã–≤–∞—é—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç —ç—Ç–æ
        return []